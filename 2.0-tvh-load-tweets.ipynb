{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "from ekphrasis.classes.tokenizer import SocialTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path\n",
    "path = '/home/tim/Documents/Data/tweets/EI-reg-En-train'\n",
    "file = 'EI-reg-En-anger-train.txt'\n",
    "\n",
    "\n",
    "# Create dataframe\n",
    "df = pd.read_csv(os.path.join(path,file),delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Affect Dimension</th>\n",
       "      <th>Intensity Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-En-10264</td>\n",
       "      <td>@xandraaa5 @amayaallyn6 shut up hashtags are c...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-En-10072</td>\n",
       "      <td>it makes me so fucking irate jesus. nobody is ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-En-11383</td>\n",
       "      <td>Lol Adam the Bull with his fake outrage...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-En-11102</td>\n",
       "      <td>@THATSSHAWTYLO passed away early this morning ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-En-11506</td>\n",
       "      <td>@Kristiann1125 lol wow i was gonna say really?...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID                                              Tweet  \\\n",
       "0  2017-En-10264  @xandraaa5 @amayaallyn6 shut up hashtags are c...   \n",
       "1  2017-En-10072  it makes me so fucking irate jesus. nobody is ...   \n",
       "2  2017-En-11383         Lol Adam the Bull with his fake outrage...   \n",
       "3  2017-En-11102  @THATSSHAWTYLO passed away early this morning ...   \n",
       "4  2017-En-11506  @Kristiann1125 lol wow i was gonna say really?...   \n",
       "\n",
       "  Affect Dimension  Intensity Score  \n",
       "0            anger            0.562  \n",
       "1            anger            0.750  \n",
       "2            anger            0.417  \n",
       "3            anger            0.354  \n",
       "4            anger            0.438  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/cbaziotis/ekphrasis\n",
    "\n",
    "social_tokenizer = SocialTokenizer(lowercase=False).tokenize\n",
    "\n",
    "# Pre-process the tweets\n",
    "def tweet_pre(s):\n",
    "    return social_tokenizer(s)\n",
    "\n",
    "# Get token length\n",
    "def token_length(s):\n",
    "    return len(s)\n",
    "\n",
    "# Get the elmo embeddings\n",
    "def elmo_tweet_embedder(tokens, len_list):\n",
    "    \n",
    "    tokens_input = tokens #load a tweet\n",
    "    tokens_length = len_list # get length of tweet\n",
    "\n",
    "    #create embedding\n",
    "    embedding_tensor = elmo(inputs={\"tokens\":tokens_input,\"sequence_len\":tokens_length},\n",
    "                            signature=\"tokens\", as_dict=True)[\"word_emb\"] # <-- passing in a list instead of [word]\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        embedding = sess.run(embedding_tensor)\n",
    "        return embedding\n",
    "\n",
    "# Create \"embedding lists\" of equal size -- pad with empty characters, e.g. \"\"\n",
    "# https://stackoverflow.com/questions/24066904/most-pythonic-way-to-extend-a-list-to-exactly-a-certain-length\n",
    "def pad_list(some_list, target_len):\n",
    "    return some_list[:target_len] + [\"\"]*(target_len - len(some_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['trans'] = df['Tweet'].apply(tweet_pre)\n",
    "df['len'] = df['trans'].apply(token_length)\n",
    "# df['embedding'] = df['trans'].apply(elmo_tweet_embedder)\n",
    "\n",
    "# Find the tweet with the longest length\n",
    "m = df['len'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = df['trans'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@xandraaa5', '@amayaallyn6', 'shut', 'up', 'hashtags', 'are', 'cool', '#offended', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "print(pad_list(l,m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['len'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Affect Dimension</th>\n",
       "      <th>Intensity Score</th>\n",
       "      <th>trans</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-En-10264</td>\n",
       "      <td>@xandraaa5 @amayaallyn6 shut up hashtags are c...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.562</td>\n",
       "      <td>[@xandraaa5, @amayaallyn6, shut, up, hashtags,...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-En-10072</td>\n",
       "      <td>it makes me so fucking irate jesus. nobody is ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.750</td>\n",
       "      <td>[it, makes, me, so, fucking, irate, jesus, ., ...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-En-11383</td>\n",
       "      <td>Lol Adam the Bull with his fake outrage...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.417</td>\n",
       "      <td>[Lol, Adam, the, Bull, with, his, fake, outrag...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-En-11102</td>\n",
       "      <td>@THATSSHAWTYLO passed away early this morning ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.354</td>\n",
       "      <td>[@THATSSHAWTYLO, passed, away, early, this, mo...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-En-11506</td>\n",
       "      <td>@Kristiann1125 lol wow i was gonna say really?...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.438</td>\n",
       "      <td>[@Kristiann1125, lol, wow, i, was, gonna, say,...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017-En-10779</td>\n",
       "      <td>I need a üç±sushi dateüçô @AnzalduaG üçùan olive gua...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.271</td>\n",
       "      <td>[I, need, a, üç±, sushi, date, üçô, @AnzalduaG, üçù,...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017-En-11588</td>\n",
       "      <td>And Republicans, you, namely Graham, Flake, Sa...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.354</td>\n",
       "      <td>[And, Republicans, ,, you, ,, namely, Graham, ...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017-En-11282</td>\n",
       "      <td>@leepg \\n\\nLike a rabid dog I pulled out the b...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.333</td>\n",
       "      <td>[@leepg, \\, n, \\, nLike, a, rabid, dog, I, pul...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017-En-11507</td>\n",
       "      <td>@MisterAK47 it's very telling that racist bigo...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.556</td>\n",
       "      <td>[@MisterAK47, it, ', s, very, telling, that, r...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017-En-10849</td>\n",
       "      <td>Follow up. Follow through. Be #relentless. #su...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.125</td>\n",
       "      <td>[Follow, up, ., Follow, through, ., Be, #relen...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2017-En-10640</td>\n",
       "      <td>@JustinRow10 dude the new madden 17? Haha</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.231</td>\n",
       "      <td>[@JustinRow10, dude, the, new, madden, 17, ?, ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017-En-10946</td>\n",
       "      <td>@moocowward @mrsajhargreaves @Melly77 @GaryBar...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.583</td>\n",
       "      <td>[@moocowward, @mrsajhargreaves, @Melly77, @Gar...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2017-En-10940</td>\n",
       "      <td>Lol little things like that make me so angry x</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.604</td>\n",
       "      <td>[Lol, little, things, like, that, make, me, so...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2017-En-11456</td>\n",
       "      <td>One more day tiff.. One more day!</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.208</td>\n",
       "      <td>[One, more, day, tiff, ., ., One, more, day, !]</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2017-En-10869</td>\n",
       "      <td>Me being on my dean really saving a lot of ppl...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.348</td>\n",
       "      <td>[Me, being, on, my, dean, really, saving, a, l...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2017-En-10514</td>\n",
       "      <td>Who knew softballs could sting so bad? Jimmy F...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.414</td>\n",
       "      <td>[Who, knew, softballs, could, sting, so, bad, ...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2017-En-10448</td>\n",
       "      <td>Women don't like girls because we resent them ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.479</td>\n",
       "      <td>[Women, don, ', t, like, girls, because, we, r...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2017-En-21354</td>\n",
       "      <td>@brendancoots where's your outrage that your p...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.766</td>\n",
       "      <td>[@brendancoots, where, ', s, your, outrage, th...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2017-En-11609</td>\n",
       "      <td>I swear I got anger issues but my heart big AF...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.604</td>\n",
       "      <td>[I, swear, I, got, anger, issues, but, my, hea...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2017-En-10537</td>\n",
       "      <td>75' Tierney reaches a deep cross to the back p...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.438</td>\n",
       "      <td>[75, ', Tierney, reaches, a, deep, cross, to, ...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2017-En-11088</td>\n",
       "      <td>This is a joke @SomersetCCC #fuming</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.688</td>\n",
       "      <td>[This, is, a, joke, @SomersetCCC, #fuming]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2017-En-10127</td>\n",
       "      <td>I just love it when people make plans for me w...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.688</td>\n",
       "      <td>[I, just, love, it, when, people, make, plans,...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2017-En-11061</td>\n",
       "      <td>Be quick to #listen, slow to #speak, and slow ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.121</td>\n",
       "      <td>[Be, quick, to, #listen, ,, slow, to, #speak, ...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2017-En-10563</td>\n",
       "      <td>@Sargon_of_Akkad It'll be like burning rap alb...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.417</td>\n",
       "      <td>[@Sargon_of_Akkad, It, ', ll, be, like, burnin...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2017-En-10184</td>\n",
       "      <td>@Daniel_Sankey @hayleyp79 Haha.... Actually, a...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.472</td>\n",
       "      <td>[@Daniel_Sankey, @hayleyp79, Haha, ., ., ., .,...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2017-En-10378</td>\n",
       "      <td>@OstinOng YUUUHH üôÑüò≠ plus clin ep and prevmed u...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.521</td>\n",
       "      <td>[@OstinOng, YUUUHH, üôÑ, üò≠, plus, clin, ep, and,...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2017-En-10689</td>\n",
       "      <td>my wasp sting is so itchy</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.356</td>\n",
       "      <td>[my, wasp, sting, is, so, itchy]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2017-En-10631</td>\n",
       "      <td>Grateful for all the hungry people in my life!...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.396</td>\n",
       "      <td>[Grateful, for, all, the, hungry, people, in, ...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2017-En-11107</td>\n",
       "      <td>@jonfavs Don King is an insult to the intellig...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.542</td>\n",
       "      <td>[@jonfavs, Don, King, is, an, insult, to, the,...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2017-En-11530</td>\n",
       "      <td>@Arsenal Giroud's beard is making me angry.</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.625</td>\n",
       "      <td>[@Arsenal, Giroud, ', s, beard, is, making, me...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671</th>\n",
       "      <td>2017-En-10791</td>\n",
       "      <td>ESPN just assumed I wanted their free magazines</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.271</td>\n",
       "      <td>[ESPN, just, assumed, I, wanted, their, free, ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>2017-En-11252</td>\n",
       "      <td>Why did Alex just growl at me.. üòÇüòÇüòÇ</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.312</td>\n",
       "      <td>[Why, did, Alex, just, growl, at, me, ., ., üòÇ,...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>2017-En-10281</td>\n",
       "      <td>Have wee pop socks on and they KEEP FALLING OF...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.562</td>\n",
       "      <td>[Have, wee, pop, socks, on, and, they, KEEP, F...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>2017-En-11387</td>\n",
       "      <td>Aidy: *has a physics question*\\nAidy: '... ok,...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.319</td>\n",
       "      <td>[Aidy, :, *, has, a, physics, question, *\\, nA...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>2017-En-10565</td>\n",
       "      <td>@SlaveGuinevere its more of a little prick tha...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.417</td>\n",
       "      <td>[@SlaveGuinevere, its, more, of, a, little, pr...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1676</th>\n",
       "      <td>2017-En-11373</td>\n",
       "      <td>#TheWordOfGOD #taught, #preached #correctly wi...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.438</td>\n",
       "      <td>[#TheWordOfGOD, #taught, ,, #preached, #correc...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>2017-En-10115</td>\n",
       "      <td>A @FirstBSA not turning up? Why am I not surpr...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.688</td>\n",
       "      <td>[A, @FirstBSA, not, turning, up, ?, Why, am, I...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>2017-En-11436</td>\n",
       "      <td>@Bungie spent over 2 fucking hours and still c...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.812</td>\n",
       "      <td>[@Bungie, spent, over, 2, fucking, hours, and,...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>2017-En-10790</td>\n",
       "      <td>@serendipity127_ @zombiecalorie @Angel_Eyes66 ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.271</td>\n",
       "      <td>[@serendipity127_, @zombiecalorie, @Angel_Eyes...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>2017-En-10232</td>\n",
       "      <td>@xxmariab listen yh don't provoke me cos I'll ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.604</td>\n",
       "      <td>[@xxmariab, listen, yh, don, ', t, provoke, me...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>2017-En-10110</td>\n",
       "      <td>@jennylhowe I am angry at the student for bein...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.708</td>\n",
       "      <td>[@jennylhowe, I, am, angry, at, the, student, ...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>2017-En-11593</td>\n",
       "      <td>Changed my clothes at work and had my pre-work...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.458</td>\n",
       "      <td>[Changed, my, clothes, at, work, and, had, my,...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>2017-En-10077</td>\n",
       "      <td>What the fuck am I supposed to do with no lunc...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.729</td>\n",
       "      <td>[What, the, fuck, am, I, supposed, to, do, wit...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>2017-En-11669</td>\n",
       "      <td>i swear to god the worst drug is loving someon...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.375</td>\n",
       "      <td>[i, swear, to, god, the, worst, drug, is, lovi...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>2017-En-40749</td>\n",
       "      <td>@Lesdoggg take me with you!! JK. Have fun, rel...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.271</td>\n",
       "      <td>[@Lesdoggg, take, me, with, you, !, !, JK, ., ...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1686</th>\n",
       "      <td>2017-En-11165</td>\n",
       "      <td>The outrage over Kessel's tweet by butthurt US...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.354</td>\n",
       "      <td>[The, outrage, over, Kessel, ', s, tweet, by, ...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687</th>\n",
       "      <td>2017-En-11617</td>\n",
       "      <td>@Plasma_Assassin @ArmouredDove @BallsOnY0u N-n...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.438</td>\n",
       "      <td>[@Plasma_Assassin, @ArmouredDove, @BallsOnY0u,...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1688</th>\n",
       "      <td>2017-En-11227</td>\n",
       "      <td>smh customers getting angry at me bc i aint go...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.729</td>\n",
       "      <td>[smh, customers, getting, angry, at, me, bc, i...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1689</th>\n",
       "      <td>2017-En-10293</td>\n",
       "      <td>if we let that in id be fuming poor keeping</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.562</td>\n",
       "      <td>[if, we, let, that, in, id, be, fuming, poor, ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690</th>\n",
       "      <td>2017-En-10519</td>\n",
       "      <td>@marthalyssa yep. LOL</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.438</td>\n",
       "      <td>[@marthalyssa, yep, ., LOL]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691</th>\n",
       "      <td>2017-En-10397</td>\n",
       "      <td>@iamsrk what's up w the gender bias? #indignan...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.500</td>\n",
       "      <td>[@iamsrk, what, ', s, up, w, the, gender, bias...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1692</th>\n",
       "      <td>2017-En-10042</td>\n",
       "      <td>SOMEONE LET SNAKES IN MY HOUSE, I BET IT @Ya_B...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.771</td>\n",
       "      <td>[SOMEONE, LET, SNAKES, IN, MY, HOUSE, ,, I, BE...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1693</th>\n",
       "      <td>2017-En-10008</td>\n",
       "      <td>@TeamShanny legit why i am so furious with him...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.875</td>\n",
       "      <td>[@TeamShanny, legit, why, i, am, so, furious, ...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1694</th>\n",
       "      <td>2017-En-10239</td>\n",
       "      <td>@aGirlHasNo_Name @MdlMurray shot by black poli...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.583</td>\n",
       "      <td>[@aGirlHasNo_Name, @MdlMurray, shot, by, black...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>2017-En-11623</td>\n",
       "      <td>I think it's time to change my #irate motif, n...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.417</td>\n",
       "      <td>[I, think, it, ', s, time, to, change, my, #ir...</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>2017-En-11110</td>\n",
       "      <td>Got a $20 tip from a drunk Uber passenger. Tod...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.708</td>\n",
       "      <td>[Got, a, $20, tip, from, a, drunk, Uber, passe...</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>2017-En-11497</td>\n",
       "      <td>@Claymakerbigsi @toghar11 @scott_mulligan_ @Bo...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.625</td>\n",
       "      <td>[@Claymakerbigsi, @toghar11, @scott_mulligan_,...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>2017-En-10539</td>\n",
       "      <td>@vladfucker69 i look rabid</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.472</td>\n",
       "      <td>[@vladfucker69, i, look, rabid]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>2017-En-10468</td>\n",
       "      <td>@m_t_f_72 I'm not surprised, I would be fuming! üò§</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.479</td>\n",
       "      <td>[@m_t_f_72, I, ', m, not, surprised, ,, I, wou...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>2017-En-40995</td>\n",
       "      <td>@MarianKeyes the pout tips me over the edge. I...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.490</td>\n",
       "      <td>[@MarianKeyes, the, pout, tips, me, over, the,...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1701 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID                                              Tweet  \\\n",
       "0     2017-En-10264  @xandraaa5 @amayaallyn6 shut up hashtags are c...   \n",
       "1     2017-En-10072  it makes me so fucking irate jesus. nobody is ...   \n",
       "2     2017-En-11383         Lol Adam the Bull with his fake outrage...   \n",
       "3     2017-En-11102  @THATSSHAWTYLO passed away early this morning ...   \n",
       "4     2017-En-11506  @Kristiann1125 lol wow i was gonna say really?...   \n",
       "5     2017-En-10779  I need a üç±sushi dateüçô @AnzalduaG üçùan olive gua...   \n",
       "6     2017-En-11588  And Republicans, you, namely Graham, Flake, Sa...   \n",
       "7     2017-En-11282  @leepg \\n\\nLike a rabid dog I pulled out the b...   \n",
       "8     2017-En-11507  @MisterAK47 it's very telling that racist bigo...   \n",
       "9     2017-En-10849  Follow up. Follow through. Be #relentless. #su...   \n",
       "10    2017-En-10640          @JustinRow10 dude the new madden 17? Haha   \n",
       "11    2017-En-10946  @moocowward @mrsajhargreaves @Melly77 @GaryBar...   \n",
       "12    2017-En-10940     Lol little things like that make me so angry x   \n",
       "13    2017-En-11456                  One more day tiff.. One more day!   \n",
       "14    2017-En-10869  Me being on my dean really saving a lot of ppl...   \n",
       "15    2017-En-10514  Who knew softballs could sting so bad? Jimmy F...   \n",
       "16    2017-En-10448  Women don't like girls because we resent them ...   \n",
       "17    2017-En-21354  @brendancoots where's your outrage that your p...   \n",
       "18    2017-En-11609  I swear I got anger issues but my heart big AF...   \n",
       "19    2017-En-10537  75' Tierney reaches a deep cross to the back p...   \n",
       "20    2017-En-11088                This is a joke @SomersetCCC #fuming   \n",
       "21    2017-En-10127  I just love it when people make plans for me w...   \n",
       "22    2017-En-11061  Be quick to #listen, slow to #speak, and slow ...   \n",
       "23    2017-En-10563  @Sargon_of_Akkad It'll be like burning rap alb...   \n",
       "24    2017-En-10184  @Daniel_Sankey @hayleyp79 Haha.... Actually, a...   \n",
       "25    2017-En-10378  @OstinOng YUUUHH üôÑüò≠ plus clin ep and prevmed u...   \n",
       "26    2017-En-10689                          my wasp sting is so itchy   \n",
       "27    2017-En-10631  Grateful for all the hungry people in my life!...   \n",
       "28    2017-En-11107  @jonfavs Don King is an insult to the intellig...   \n",
       "29    2017-En-11530        @Arsenal Giroud's beard is making me angry.   \n",
       "...             ...                                                ...   \n",
       "1671  2017-En-10791   ESPN just assumed I wanted their free magazines    \n",
       "1672  2017-En-11252                Why did Alex just growl at me.. üòÇüòÇüòÇ   \n",
       "1673  2017-En-10281  Have wee pop socks on and they KEEP FALLING OF...   \n",
       "1674  2017-En-11387  Aidy: *has a physics question*\\nAidy: '... ok,...   \n",
       "1675  2017-En-10565  @SlaveGuinevere its more of a little prick tha...   \n",
       "1676  2017-En-11373  #TheWordOfGOD #taught, #preached #correctly wi...   \n",
       "1677  2017-En-10115  A @FirstBSA not turning up? Why am I not surpr...   \n",
       "1678  2017-En-11436  @Bungie spent over 2 fucking hours and still c...   \n",
       "1679  2017-En-10790  @serendipity127_ @zombiecalorie @Angel_Eyes66 ...   \n",
       "1680  2017-En-10232  @xxmariab listen yh don't provoke me cos I'll ...   \n",
       "1681  2017-En-10110  @jennylhowe I am angry at the student for bein...   \n",
       "1682  2017-En-11593  Changed my clothes at work and had my pre-work...   \n",
       "1683  2017-En-10077  What the fuck am I supposed to do with no lunc...   \n",
       "1684  2017-En-11669  i swear to god the worst drug is loving someon...   \n",
       "1685  2017-En-40749  @Lesdoggg take me with you!! JK. Have fun, rel...   \n",
       "1686  2017-En-11165  The outrage over Kessel's tweet by butthurt US...   \n",
       "1687  2017-En-11617  @Plasma_Assassin @ArmouredDove @BallsOnY0u N-n...   \n",
       "1688  2017-En-11227  smh customers getting angry at me bc i aint go...   \n",
       "1689  2017-En-10293        if we let that in id be fuming poor keeping   \n",
       "1690  2017-En-10519                             @marthalyssa yep. LOL    \n",
       "1691  2017-En-10397  @iamsrk what's up w the gender bias? #indignan...   \n",
       "1692  2017-En-10042  SOMEONE LET SNAKES IN MY HOUSE, I BET IT @Ya_B...   \n",
       "1693  2017-En-10008  @TeamShanny legit why i am so furious with him...   \n",
       "1694  2017-En-10239  @aGirlHasNo_Name @MdlMurray shot by black poli...   \n",
       "1695  2017-En-11623  I think it's time to change my #irate motif, n...   \n",
       "1696  2017-En-11110  Got a $20 tip from a drunk Uber passenger. Tod...   \n",
       "1697  2017-En-11497  @Claymakerbigsi @toghar11 @scott_mulligan_ @Bo...   \n",
       "1698  2017-En-10539                         @vladfucker69 i look rabid   \n",
       "1699  2017-En-10468  @m_t_f_72 I'm not surprised, I would be fuming! üò§   \n",
       "1700  2017-En-40995  @MarianKeyes the pout tips me over the edge. I...   \n",
       "\n",
       "     Affect Dimension  Intensity Score  \\\n",
       "0               anger            0.562   \n",
       "1               anger            0.750   \n",
       "2               anger            0.417   \n",
       "3               anger            0.354   \n",
       "4               anger            0.438   \n",
       "5               anger            0.271   \n",
       "6               anger            0.354   \n",
       "7               anger            0.333   \n",
       "8               anger            0.556   \n",
       "9               anger            0.125   \n",
       "10              anger            0.231   \n",
       "11              anger            0.583   \n",
       "12              anger            0.604   \n",
       "13              anger            0.208   \n",
       "14              anger            0.348   \n",
       "15              anger            0.414   \n",
       "16              anger            0.479   \n",
       "17              anger            0.766   \n",
       "18              anger            0.604   \n",
       "19              anger            0.438   \n",
       "20              anger            0.688   \n",
       "21              anger            0.688   \n",
       "22              anger            0.121   \n",
       "23              anger            0.417   \n",
       "24              anger            0.472   \n",
       "25              anger            0.521   \n",
       "26              anger            0.356   \n",
       "27              anger            0.396   \n",
       "28              anger            0.542   \n",
       "29              anger            0.625   \n",
       "...               ...              ...   \n",
       "1671            anger            0.271   \n",
       "1672            anger            0.312   \n",
       "1673            anger            0.562   \n",
       "1674            anger            0.319   \n",
       "1675            anger            0.417   \n",
       "1676            anger            0.438   \n",
       "1677            anger            0.688   \n",
       "1678            anger            0.812   \n",
       "1679            anger            0.271   \n",
       "1680            anger            0.604   \n",
       "1681            anger            0.708   \n",
       "1682            anger            0.458   \n",
       "1683            anger            0.729   \n",
       "1684            anger            0.375   \n",
       "1685            anger            0.271   \n",
       "1686            anger            0.354   \n",
       "1687            anger            0.438   \n",
       "1688            anger            0.729   \n",
       "1689            anger            0.562   \n",
       "1690            anger            0.438   \n",
       "1691            anger            0.500   \n",
       "1692            anger            0.771   \n",
       "1693            anger            0.875   \n",
       "1694            anger            0.583   \n",
       "1695            anger            0.417   \n",
       "1696            anger            0.708   \n",
       "1697            anger            0.625   \n",
       "1698            anger            0.472   \n",
       "1699            anger            0.479   \n",
       "1700            anger            0.490   \n",
       "\n",
       "                                                  trans  len  \n",
       "0     [@xandraaa5, @amayaallyn6, shut, up, hashtags,...    8  \n",
       "1     [it, makes, me, so, fucking, irate, jesus, ., ...   21  \n",
       "2     [Lol, Adam, the, Bull, with, his, fake, outrag...   11  \n",
       "3     [@THATSSHAWTYLO, passed, away, early, this, mo...   28  \n",
       "4     [@Kristiann1125, lol, wow, i, was, gonna, say,...   26  \n",
       "5     [I, need, a, üç±, sushi, date, üçô, @AnzalduaG, üçù,...   22  \n",
       "6     [And, Republicans, ,, you, ,, namely, Graham, ...   31  \n",
       "7     [@leepg, \\, n, \\, nLike, a, rabid, dog, I, pul...   32  \n",
       "8     [@MisterAK47, it, ', s, very, telling, that, r...   28  \n",
       "9     [Follow, up, ., Follow, through, ., Be, #relen...   10  \n",
       "10    [@JustinRow10, dude, the, new, madden, 17, ?, ...    8  \n",
       "11    [@moocowward, @mrsajhargreaves, @Melly77, @Gar...   30  \n",
       "12    [Lol, little, things, like, that, make, me, so...   10  \n",
       "13      [One, more, day, tiff, ., ., One, more, day, !]   10  \n",
       "14    [Me, being, on, my, dean, really, saving, a, l...   29  \n",
       "15    [Who, knew, softballs, could, sting, so, bad, ...   29  \n",
       "16    [Women, don, ', t, like, girls, because, we, r...   23  \n",
       "17    [@brendancoots, where, ', s, your, outrage, th...   24  \n",
       "18    [I, swear, I, got, anger, issues, but, my, hea...   14  \n",
       "19    [75, ', Tierney, reaches, a, deep, cross, to, ...   26  \n",
       "20           [This, is, a, joke, @SomersetCCC, #fuming]    6  \n",
       "21    [I, just, love, it, when, people, make, plans,...   18  \n",
       "22    [Be, quick, to, #listen, ,, slow, to, #speak, ...   13  \n",
       "23    [@Sargon_of_Akkad, It, ', ll, be, like, burnin...   32  \n",
       "24    [@Daniel_Sankey, @hayleyp79, Haha, ., ., ., .,...   22  \n",
       "25    [@OstinOng, YUUUHH, üôÑ, üò≠, plus, clin, ep, and,...   12  \n",
       "26                     [my, wasp, sting, is, so, itchy]    6  \n",
       "27    [Grateful, for, all, the, hungry, people, in, ...   29  \n",
       "28    [@jonfavs, Don, King, is, an, insult, to, the,...   20  \n",
       "29    [@Arsenal, Giroud, ', s, beard, is, making, me...   10  \n",
       "...                                                 ...  ...  \n",
       "1671  [ESPN, just, assumed, I, wanted, their, free, ...    8  \n",
       "1672  [Why, did, Alex, just, growl, at, me, ., ., üòÇ,...   12  \n",
       "1673  [Have, wee, pop, socks, on, and, they, KEEP, F...   13  \n",
       "1674  [Aidy, :, *, has, a, physics, question, *\\, nA...   32  \n",
       "1675  [@SlaveGuinevere, its, more, of, a, little, pr...   30  \n",
       "1676  [#TheWordOfGOD, #taught, ,, #preached, #correc...   17  \n",
       "1677  [A, @FirstBSA, not, turning, up, ?, Why, am, I...   18  \n",
       "1678  [@Bungie, spent, over, 2, fucking, hours, and,...   20  \n",
       "1679  [@serendipity127_, @zombiecalorie, @Angel_Eyes...   12  \n",
       "1680  [@xxmariab, listen, yh, don, ', t, provoke, me...   15  \n",
       "1681  [@jennylhowe, I, am, angry, at, the, student, ...   30  \n",
       "1682  [Changed, my, clothes, at, work, and, had, my,...   32  \n",
       "1683  [What, the, fuck, am, I, supposed, to, do, wit...   27  \n",
       "1684  [i, swear, to, god, the, worst, drug, is, lovi...   25  \n",
       "1685  [@Lesdoggg, take, me, with, you, !, !, JK, ., ...   35  \n",
       "1686  [The, outrage, over, Kessel, ', s, tweet, by, ...   14  \n",
       "1687  [@Plasma_Assassin, @ArmouredDove, @BallsOnY0u,...   12  \n",
       "1688  [smh, customers, getting, angry, at, me, bc, i...   29  \n",
       "1689  [if, we, let, that, in, id, be, fuming, poor, ...   10  \n",
       "1690                        [@marthalyssa, yep, ., LOL]    4  \n",
       "1691  [@iamsrk, what, ', s, up, w, the, gender, bias...   29  \n",
       "1692  [SOMEONE, LET, SNAKES, IN, MY, HOUSE, ,, I, BE...   24  \n",
       "1693  [@TeamShanny, legit, why, i, am, so, furious, ...   16  \n",
       "1694  [@aGirlHasNo_Name, @MdlMurray, shot, by, black...   15  \n",
       "1695  [I, think, it, ', s, time, to, change, my, #ir...   37  \n",
       "1696  [Got, a, $20, tip, from, a, drunk, Uber, passe...   34  \n",
       "1697  [@Claymakerbigsi, @toghar11, @scott_mulligan_,...   21  \n",
       "1698                    [@vladfucker69, i, look, rabid]    4  \n",
       "1699  [@m_t_f_72, I, ', m, not, surprised, ,, I, wou...   13  \n",
       "1700  [@MarianKeyes, the, pout, tips, me, over, the,...   31  \n",
       "\n",
       "[1701 rows x 6 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Affect Dimension</th>\n",
       "      <th>Intensity Score</th>\n",
       "      <th>trans</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-En-10264</td>\n",
       "      <td>@xandraaa5 @amayaallyn6 shut up hashtags are c...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.562</td>\n",
       "      <td>[@xandraaa5, @amayaallyn6, shut, up, hashtags,...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-En-10072</td>\n",
       "      <td>it makes me so fucking irate jesus. nobody is ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.750</td>\n",
       "      <td>[it, makes, me, so, fucking, irate, jesus, ., ...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID                                              Tweet  \\\n",
       "0  2017-En-10264  @xandraaa5 @amayaallyn6 shut up hashtags are c...   \n",
       "1  2017-En-10072  it makes me so fucking irate jesus. nobody is ...   \n",
       "\n",
       "  Affect Dimension  Intensity Score  \\\n",
       "0            anger            0.562   \n",
       "1            anger            0.750   \n",
       "\n",
       "                                               trans  len  \n",
       "0  [@xandraaa5, @amayaallyn6, shut, up, hashtags,...    8  \n",
       "1  [it, makes, me, so, fucking, irate, jesus, ., ...   21  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.iloc[:2]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_len = df2['len'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['@xandraaa5',\n",
       "  '@amayaallyn6',\n",
       "  'shut',\n",
       "  'up',\n",
       "  'hashtags',\n",
       "  'are',\n",
       "  'cool',\n",
       "  '#offended'],\n",
       " ['it',\n",
       "  'makes',\n",
       "  'me',\n",
       "  'so',\n",
       "  'fucking',\n",
       "  'irate',\n",
       "  'jesus',\n",
       "  '.',\n",
       "  'nobody',\n",
       "  'is',\n",
       "  'calling',\n",
       "  'ppl',\n",
       "  'who',\n",
       "  'like',\n",
       "  'hajime',\n",
       "  'abusive',\n",
       "  'stop',\n",
       "  'with',\n",
       "  'the',\n",
       "  'strawmen',\n",
       "  'lmao']]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = df2['trans'].tolist()\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Argument must be a dense tensor: [['@xandraaa5', '@amayaallyn6', 'shut', 'up', 'hashtags', 'are', 'cool', '#offended'], ['it', 'makes', 'me', 'so', 'fucking', 'irate', 'jesus', '.', 'nobody', 'is', 'calling', 'ppl', 'who', 'like', 'hajime', 'abusive', 'stop', 'with', 'the', 'strawmen', 'lmao']] - got shape [2], but wanted [2, 8].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-bc40e4465b5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0melmo_tweet_embedder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-56-582ec2b5bc02>\u001b[0m in \u001b[0;36melmo_tweet_embedder\u001b[0;34m(tokens, len_list)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m#create embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     embedding_tensor = elmo(inputs={\"tokens\":tokens_input,\"sequence_len\":tokens_length},\n\u001b[0;32m---> 22\u001b[0;31m                             signature=\"tokens\", as_dict=True)[\"word_emb\"] # <-- passing in a list instead of [word]\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow_hub/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, _sentinel, signature, as_dict)\u001b[0m\n\u001b[1;32m    240\u001b[0m     dict_inputs = _convert_dict_inputs(\n\u001b[1;32m    241\u001b[0m         inputs, self._spec.get_input_info_dict(signature=signature,\n\u001b[0;32m--> 242\u001b[0;31m                                                tags=self._tags))\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     dict_outputs = self._impl.create_apply_graph(\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow_hub/module.py\u001b[0m in \u001b[0;36m_convert_dict_inputs\u001b[0;34m(inputs, tensor_info_map)\u001b[0m\n\u001b[1;32m    442\u001b[0m   \u001b[0mdict_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prepare_dict_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_info_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m   return tensor_info.convert_dict_to_compatible_tensor(dict_inputs,\n\u001b[0;32m--> 444\u001b[0;31m                                                        tensor_info_map)\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow_hub/tensor_info.py\u001b[0m in \u001b[0;36mconvert_dict_to_compatible_tensor\u001b[0;34m(values, targets)\u001b[0m\n\u001b[1;32m    146\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     result[key] = _convert_to_compatible_tensor(\n\u001b[0;32m--> 148\u001b[0;31m         value, targets[key], error_prefix=\"Can't convert %r\" % key)\n\u001b[0m\u001b[1;32m    149\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow_hub/tensor_info.py\u001b[0m in \u001b[0;36m_convert_to_compatible_tensor\u001b[0;34m(value, target, error_prefix)\u001b[0m\n\u001b[1;32m    115\u001b[0m   \"\"\"\n\u001b[1;32m    116\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor_or_indexed_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merror_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_or_indexed_slices\u001b[0;34m(value, dtype, name)\u001b[0m\n\u001b[1;32m   1267\u001b[0m   \"\"\"\n\u001b[1;32m   1268\u001b[0m   return internal_convert_to_tensor_or_indexed_slices(\n\u001b[0;32m-> 1269\u001b[0;31m       value=value, dtype=dtype, name=name, as_ref=False)\n\u001b[0m\u001b[1;32m   1270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor_or_indexed_slices\u001b[0;34m(value, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m   1305\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m     return internal_convert_to_tensor(\n\u001b[0;32m-> 1307\u001b[0;31m         value, dtype=dtype, name=name, as_ref=as_ref)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1146\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    227\u001b[0m                                          as_ref=False):\n\u001b[1;32m    228\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    206\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[1;32m    207\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[0;32m--> 208\u001b[0;31m           value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    209\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    449\u001b[0m                          \u001b[0;34m\"\"\" - got shape %s, but wanted %s.\"\"\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m                          (values, list(nparray.shape),\n\u001b[0;32m--> 451\u001b[0;31m                           _GetDenseDimensions(values)))\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# python/numpy default float type is float64. We prefer float32 instead.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Argument must be a dense tensor: [['@xandraaa5', '@amayaallyn6', 'shut', 'up', 'hashtags', 'are', 'cool', '#offended'], ['it', 'makes', 'me', 'so', 'fucking', 'irate', 'jesus', '.', 'nobody', 'is', 'calling', 'ppl', 'who', 'like', 'hajime', 'abusive', 'stop', 'with', 'the', 'strawmen', 'lmao']] - got shape [2], but wanted [2, 8]."
     ]
    }
   ],
   "source": [
    "elmo_tweet_embedder(t, t_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(t[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(df2['trans'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Argument must be a dense tensor: [['@xandraaa5', '@amayaallyn6', 'shut', 'up', 'hashtags', 'are', 'cool', '#offended'], ['it', 'makes', 'me', 'so', 'fucking', 'irate', 'jesus', '.', 'nobody', 'is', 'calling', 'ppl', 'who', 'like', 'hajime', 'abusive', 'stop', 'with', 'the', 'strawmen', 'lmao'], ['Lol', 'Adam', 'the', 'Bull', 'with', 'his', 'fake', 'outrage', '.', '.', '.'], ['@THATSSHAWTYLO', 'passed', 'away', 'early', 'this', 'morning', 'in', 'a', 'fast', 'and', 'furious', 'styled', 'car', 'crash', 'as', 'he', 'was', 'leaving', 'an', 'ATL', 'strip', 'club', '.', 'That', \"'\", 's', 'rough', 'stuff'], ['@Kristiann1125', 'lol', 'wow', 'i', 'was', 'gonna', 'say', 'really', '?', '!', 'haha', 'have', 'you', 'seen', 'chris', 'or', 'nah', '?', 'you', 'dont', 'even', 'snap', 'me', 'anymore', 'dude', '!'], ['I', 'need', 'a', 'üç±', 'sushi', 'date', 'üçô', '@AnzalduaG', 'üçù', 'an', 'olive', 'guarded', 'date', 'üßÄ', '@lexiereid369', 'and', 'a', 'üëä', 'üèº', 'Rockys', 'date', 'üçï']] - got shape [6], but wanted [6, 8].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-5ed68098b037>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#create embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m embedding_tensor = elmo(inputs={\"tokens\":tokens_input,\"sequence_len\":tokens_length},\n\u001b[0;32m----> 7\u001b[0;31m                         signature=\"tokens\", as_dict=True)[\"word_emb\"] # <-- passing in a list instead of [word]\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow_hub/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, _sentinel, signature, as_dict)\u001b[0m\n\u001b[1;32m    240\u001b[0m     dict_inputs = _convert_dict_inputs(\n\u001b[1;32m    241\u001b[0m         inputs, self._spec.get_input_info_dict(signature=signature,\n\u001b[0;32m--> 242\u001b[0;31m                                                tags=self._tags))\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     dict_outputs = self._impl.create_apply_graph(\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow_hub/module.py\u001b[0m in \u001b[0;36m_convert_dict_inputs\u001b[0;34m(inputs, tensor_info_map)\u001b[0m\n\u001b[1;32m    442\u001b[0m   \u001b[0mdict_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prepare_dict_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_info_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m   return tensor_info.convert_dict_to_compatible_tensor(dict_inputs,\n\u001b[0;32m--> 444\u001b[0;31m                                                        tensor_info_map)\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow_hub/tensor_info.py\u001b[0m in \u001b[0;36mconvert_dict_to_compatible_tensor\u001b[0;34m(values, targets)\u001b[0m\n\u001b[1;32m    146\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     result[key] = _convert_to_compatible_tensor(\n\u001b[0;32m--> 148\u001b[0;31m         value, targets[key], error_prefix=\"Can't convert %r\" % key)\n\u001b[0m\u001b[1;32m    149\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow_hub/tensor_info.py\u001b[0m in \u001b[0;36m_convert_to_compatible_tensor\u001b[0;34m(value, target, error_prefix)\u001b[0m\n\u001b[1;32m    115\u001b[0m   \"\"\"\n\u001b[1;32m    116\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor_or_indexed_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merror_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_or_indexed_slices\u001b[0;34m(value, dtype, name)\u001b[0m\n\u001b[1;32m   1267\u001b[0m   \"\"\"\n\u001b[1;32m   1268\u001b[0m   return internal_convert_to_tensor_or_indexed_slices(\n\u001b[0;32m-> 1269\u001b[0;31m       value=value, dtype=dtype, name=name, as_ref=False)\n\u001b[0m\u001b[1;32m   1270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor_or_indexed_slices\u001b[0;34m(value, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m   1305\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m     return internal_convert_to_tensor(\n\u001b[0;32m-> 1307\u001b[0;31m         value, dtype=dtype, name=name, as_ref=as_ref)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1146\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    227\u001b[0m                                          as_ref=False):\n\u001b[1;32m    228\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    206\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[1;32m    207\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[0;32m--> 208\u001b[0;31m           value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    209\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    449\u001b[0m                          \u001b[0;34m\"\"\" - got shape %s, but wanted %s.\"\"\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m                          (values, list(nparray.shape),\n\u001b[0;32m--> 451\u001b[0;31m                           _GetDenseDimensions(values)))\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# python/numpy default float type is float64. We prefer float32 instead.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Argument must be a dense tensor: [['@xandraaa5', '@amayaallyn6', 'shut', 'up', 'hashtags', 'are', 'cool', '#offended'], ['it', 'makes', 'me', 'so', 'fucking', 'irate', 'jesus', '.', 'nobody', 'is', 'calling', 'ppl', 'who', 'like', 'hajime', 'abusive', 'stop', 'with', 'the', 'strawmen', 'lmao'], ['Lol', 'Adam', 'the', 'Bull', 'with', 'his', 'fake', 'outrage', '.', '.', '.'], ['@THATSSHAWTYLO', 'passed', 'away', 'early', 'this', 'morning', 'in', 'a', 'fast', 'and', 'furious', 'styled', 'car', 'crash', 'as', 'he', 'was', 'leaving', 'an', 'ATL', 'strip', 'club', '.', 'That', \"'\", 's', 'rough', 'stuff'], ['@Kristiann1125', 'lol', 'wow', 'i', 'was', 'gonna', 'say', 'really', '?', '!', 'haha', 'have', 'you', 'seen', 'chris', 'or', 'nah', '?', 'you', 'dont', 'even', 'snap', 'me', 'anymore', 'dude', '!'], ['I', 'need', 'a', 'üç±', 'sushi', 'date', 'üçô', '@AnzalduaG', 'üçù', 'an', 'olive', 'guarded', 'date', 'üßÄ', '@lexiereid369', 'and', 'a', 'üëä', 'üèº', 'Rockys', 'date', 'üçï']] - got shape [6], but wanted [6, 8]."
     ]
    }
   ],
   "source": [
    "tokens_input = df2['trans'].tolist()#load a tweet\n",
    "\n",
    "tokens_length = df2['len'].values # get length of tweet\n",
    "\n",
    "#create embedding\n",
    "embedding_tensor = elmo(inputs={\"tokens\":tokens_input,\"sequence_len\":tokens_length},\n",
    "                        signature=\"tokens\", as_dict=True)[\"word_emb\"] # <-- passing in a list instead of [word]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    embedding = sess.run(embedding_tensor)\n",
    "    print(embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using /tmp/tfhub_modules to cache modules.\n"
     ]
    }
   ],
   "source": [
    "# Load elmo module from tensorflow-hub\n",
    "elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['embedding'] = df['trans'].apply(elmo_tweet_embedder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below script creates the embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_input = [df.iloc[3,4]] #load a tweet\n",
    "\n",
    "tokens_length = [np.shape(tokens_input)[1]] # get length of tweet\n",
    "\n",
    "#create embedding\n",
    "embedding_tensor = elmo(inputs={\"tokens\":tokens_input,\"sequence_len\":tokens_length},\n",
    "                        signature=\"tokens\", as_dict=True)[\"word_emb\"] # <-- passing in a list instead of [word]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    embedding = sess.run(embedding_tensor)\n",
    "    print(embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.iloc[:6]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['embedding'] = df2['trans'].apply(elmo_tweet_embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
